\section{Results} \label{sec:results}
We report the variability across the physician reviewers and then report the results of the predictive performance of LR and HLR models from three perspectives: \textit{overall}, \textit{per-target}, and \textit{per-physician}. Table~\ref{tab:years} summarizes the physician characteristics and the number of patients that each physician reviewed within the two diagnostic groups, AKF and ARF.

\begin{table}[htbp]
\setlength{\aboverulesep}{0.pt}
\setlength{\belowrulesep}{0.pt}
\renewcommand{\arraystretch}{1.2}
    \caption{Years of ICU experience for each physician and the number of patient cases each physician reviewed. }
    \label{tab:years}
        \vspace{3mm}
    \centering
    \scalebox{0.8}{
    % Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{tabular}{|c|c|c|}
\toprule
\multicolumn{1}{|c|}{\multirow{2}[2]{*}{\textbf{Physician identifier}}} & \multicolumn{1}{c|}{\multirow{2}[2]{*}{\textbf{Years of ICU experience}}} & \multirow{2}[2]{*}{\textbf{\# Cases reviewed (\#ARF, \#AKF)}} \\
      &       & \multicolumn{1}{c|}{} \\
\midrule
1     & $< 1$ & 15 (8, 7) \\
\midrule
2     & 1     & 15 (10, 5) \\
\midrule
3     & 3     & 12 (5, 7) \\
\midrule
4     & $< 1$ & 17 (8, 9) \\
\midrule
5     & 1     & 15 (9, 6) \\
\midrule
6     & 1     & 15 (7, 8) \\
\midrule
7     & 2     & 22 (10, 12) \\
\midrule
8     & 1     & 20 (11, 9) \\
\midrule
9     & 1     & 16 (8, 8) \\
\midrule
10    & 2     & 16 (8, 8) \\
\midrule
11    & 7     & 15 (9, 6) \\
\bottomrule
\end{tabular}%
    }
\end{table}

\subsection{Variability in information-seeking behavior}\label{sec:variability}
We define a descriptive statistic called \textit{average relevance proportion} (ARP) to measure the information-seeking behavior of each physician reviewer. An ARP value for a physician is defined as the average proportion of EMR data items that the physician sought as relevant. We calculated the ARP values over the 73 EMR data items that were used as target variables. Figure~\ref{fig:3} shows the physician ARP values separately for each of the diagnostic groups. Each circle denotes the ARP value for the corresponding physician on the x-axis and each error bar represents a 95\% confidence interval (CI) for an ARP value. In the ARF diagnosis group, the ARP CIs for physicians 1, 7, and 8 do not overlap with those of the other physicians, which indicates a potential variability in information-seeking behavior between these physicians and the rest. Similar variability is observed in the AKF group, where the ARP CIs of physicians 1, 3, 7, and 8 differ from those of the other physicians.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{./pictures/Figure3}
    \caption{
    Per-physician ARP values over 73 target variables. A blue circle denotes the ARP value and an error bar denotes a 95\% CI. The panel on the left is for ARF cases and the panel on the right is for AKF cases.
    }\label{fig:3}
\end{figure}

\subsection{Overall performance} \label{sec:overall_performance}
The overall performance of each model family (LR and HLR) was calculated by concatenating the predictions for all 73 target variables into a single vector and using that vector to compute the performance metrics. Table~\ref{tab:overall} reports the AUROC, AUPRC, and ECE for the LR and HLR models across all 73 target variables. For AUROC values, the 95\% CI and p-value were calculated using Delongâ€™s method \cite{DeLong2003,Robin2011}. The 95\% CI for AUPRC values was derived using the logit intervals method \cite{Boyd2013} and the p-value was calculated using the Wald z-test. For ECE values, we set $k=100$ in Equation~\ref{eq:1} and obtained a vector of 100 calibration errors to compute 95\% CIs and a t-test p-value. Figure~\ref{fig:4}a shows the overall ROC and calibration curves for LR and HLR models. Note that for the calibration curves, we set the number of bins to $k=10$ for better visibility.

\begin{table}[htbp]
    \centering
    \setlength{\aboverulesep}{0.1pt}
    \setlength{\belowrulesep}{0.1pt}
    \renewcommand{\arraystretch}{1.2}
    \caption{Overall AUROC, AUPRC, and ECE for LR and HLR models over all 73 target variables and across all physicians. Higher AUROC and AUPRC show better discrimination power while lower ECE denotes better probability calibration. The best values for each metric are in boldface.}
    \label{tab:overall}
    \vspace{3mm}
    \centering
    \scalebox{0.8}{
    % Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{tabular}{|c|c|c|c|}
\toprule
\textbf{Measure} & \textbf{LR} & \textbf{HLR} & \textbf{p-value} \\
\midrule
AUROC & 0.75 (0.74-0.76) & \textbf{0.81 (0.80-0.82)} & < 0.001 \\
\midrule
AUPRC & 0.665 (0.663-0.667) & \textbf{0.763 (0.762-0.765)} & < 0.001 \\
\midrule
ECE   & 0.16 (0.14-0.17) & \textbf{0.07 (0.06-0.08)} & < 0.001 \\
\bottomrule
\end{tabular}%
}
\end{table}


\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{./pictures/Figure4}
    \caption{
    \textbf{(a)} ROC, precision-recall, and calibration curves over all 73 target variables across all physicians. For the calibration curves, the closer a curve is located to the dotted diagonal line, the more calibrated the corresponding approach is. \textbf{(b)} Distribution of AUROC, AUPRC, and ECE values for 73 models. Forward-slash hatches in blue represent the distributions for HLR models and backslash hatches in orange denote the distributions for LR models. The AUROC and AUPRC distributions for HLR models are right-skewed relative to the LR models, which show that HLR models generally have better discrimination power. The distribution of ECE values of HLR models is left-skewed relative to the LR models, which means that HLR models are generally better calibrated than LR models. \textbf{(c)} AUROC, AUPRC, and ECE values for each physician reviewer over all 73 models. The values for HLR models are shown in blue and the values for LR models are shown in orange. The AUROC and AUPRC values are higher for HLR models than for LR models, except for the AUROC value for physician 1. All the ECE values are lower for HLR models, which mean that HLR models are better calibrated than the LR models.
    }\label{fig:4}
\end{figure}


\subsection{Per-target performance} \label{sec:pertarget}
For per-target performance, we computed the predictive performance for each target variable, which resulted in vectors of AUROC, AUPRC, and ECE values each with a length of 73, for each model family (LR and HLR). Distributions of per-target performance measures are shown as histograms in Figure~\ref{fig:4}b for each model family. Histograms of the two model families are overlaid for better comparison. Additional details are provided in Table~\ref{tab:s1} in Appendix~\ref{sec:app_C} where AUROC, AUPRC, and ECE values are reported for each target variable.

\subsection{Per-physician  performance} \label{sec:perphysician}
For per-physician performance, we computed the predictive performance for each physician, which resulted in 11 AUROC, AUPRC, and ECE values for each model family (LR and HLR). Figure~\ref{fig:4}c presents the per-physician bar plots of the performance measure values; the bars for HLR and LR models are displayed side by side for better comparison. Per-physician calibration curves are presented in Figure~\ref{fig:s1} in Appendix~\ref{sec:app_C}.
